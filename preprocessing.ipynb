{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directory(train_dir):\n",
    "    # create directory for each dataset\n",
    "    if not os.path.exists(os.path.join(train_dir, 'train')):\n",
    "        os.mkdir(os.path.join(train_dir, 'train'))\n",
    "    \n",
    "    if not os.path.exists(os.path.join(train_dir, 'valid')):\n",
    "        os.mkdir(os.path.join(train_dir, 'train', 'valid'))\n",
    "    \n",
    "    labels = ['cat', 'dog']\n",
    "    \n",
    "    # create directory for each label\n",
    "    for label in labels:\n",
    "        if not os.path.exists(os.path.join(train_dir, 'train', label)):\n",
    "            os.mkdir(os.path.join(train_dir, 'train', label))\n",
    "            \n",
    "    for label in labels:\n",
    "        if not os.path.exists(os.path.join(train_dir, 'valid', label)):\n",
    "            os.mkdir(os.path.join(train_dir, 'valid', label))\n",
    "            \n",
    "\n",
    "def build_file_structure(train_dir, train_ratio):\n",
    "    # ratio of train/valid dataset\n",
    "    files = glob.glob(os.path.join(train_dir, '*.jpg'))\n",
    "    # shuffle the whole training data\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    boundary = (int)(len(files) * train_ratio)\n",
    "\n",
    "    make_directory(train_dir)\n",
    "    \n",
    "    \n",
    "    # process train dataset\n",
    "    for file in files[:boundary]:\n",
    "        filenames = file.split('\\\\')[-1].split('.')\n",
    "        os.rename(file, os.path.join(train_dir, 'train', filenames[0], filenames[1]+'.'+filenames[2]))\n",
    "        \n",
    "        \n",
    "    # process valid dataset\n",
    "    for file in files[boundary:]:\n",
    "        filenames = file.split('\\\\')[-1].split('.')\n",
    "        os.rename(file, os.path.join(train_dir, 'valid', filenames[0], filenames[1]+'.'+filenames[2]))\n",
    "\n",
    "\n",
    "def dataset_load(dataset_dir, batch_size, shuffled, num_workers):\n",
    "    images = ImageFolder(dataset_dir, \n",
    "                         transforms.Compose([\n",
    "                             transforms.Resize((224, 224)),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                  std=[0.229, 0.224, 0.225])\n",
    "                         ]))\n",
    "    return DataLoader(images,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffled,\n",
    "                      num_workers=num_workers)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = dataset_load('./dogs-vs-cats-redux-kernels-edition/train/train', 64, True, 3)\n",
    "valid_data_gen = dataset_load('./dogs-vs-cats-redux-kernels-edition/train/valid', 64, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
